%% !TeX root = filename
\documentclass[12pt,letterpaper,reqno,oneside]{amsart}
\usepackage{standalone}
\usepackage{subfiles}
\usepackage{subcaption}
\usepackage{dcolumn}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish,es-nodecimaldot,safe=none]{babel}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{threeparttable} % for table notes
\usepackage[backend=biber,
            style=authoryear,
            natbib=true,
            maxcitenames=2,
            mincitenames=1,
            maxbibnames=99,
            sorting=nyt]{biblatex}
\addbibresource[label=main]{references.bib}
\usepackage{mdframed}
\usepackage{amsfonts}
\usepackage{physics}
% \usepackage{cmbright}
\usepackage{calc}
\usepackage{datetime}
\usepackage[style=american]{csquotes}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsthm}
% \usepackage[extreme]{savetrees}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{xfrac}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{marginnote}
\usepackage{listings}
\input{stata-lstlisting.tex}
% Configure listings to use the same font as \texttt
\lstset{
  basicstyle=\ttfamily,
  columns=flexible,
  keepspaces=true,
  breaklines=true,
  frame=none,
  backgroundcolor=\color{gray!10}
}
\usepackage[shortlabels]{enumitem}
\usepackage[hidelinks]{hyperref}
%\usepackage[useregional=text]{datetime2}
\usepackage{placeins}
\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{2}
\pgfplotsset{compat=1.5}
% \setlength\parindent{0pt}


% Equations numbers are preceded by subsection
% \numberwithin{equation}{subsection}

% \theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}[subsection]
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}[prop]
\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}[subsection]
% Define a new style for the 'problem' environment
\newtheoremstyle{problemstyle}
  {0pt} % Space above
  {\topsep} % Space below
  {} % Body font
  {0pt} % Indent amount
  {\bfseries} % Theorem head font
  {.} % Punctuation after theorem head
  {.5em} % Space after theorem head
  {} % Theorem head spec (can be left empty)

\theoremstyle{problemstyle} % Apply the new style for 'problem'
\newtheorem{problem}{Problema}
\newtheorem{appendixproblem}{Problem}
\theoremstyle{definition} % Revert to 'definition' style for subsequent environments
\newtheorem{solution}{Solución}[problem]
\newtheorem{appendixsolution}{Solution}[appendixproblem]
\renewcommand{\theappendixproblem}{\thesection}
\renewcommand{\theappendixsolution}{\theappendixproblem~(\alph{appendixsolution})}
\renewcommand{\thesolution}{\theproblem~(\alph{solution})}

% Section styling
% \renewcommand\thesection{\arabic{section}}
% \renewcommand\thesubsection{\thesection.\Alph{subsection}}
% \renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

% Operators
\DeclareMathOperator{\ar}{AR}
\DeclareMathOperator{\ma}{MA}
\DeclareMathOperator{\arma}{ARMA}
\DeclareMathOperator{\garch}{GARCH}
\DeclareMathOperator{\plim}{p\!\lim}


\makeatletter
\renewcommand{\@setdate}{\datename~\@date}
\renewcommand{\datename}{\textit{Fecha:}}
\makeatother

\begin{document}
\author[F. I. Tappata]{Felipe. I. Tappata}
% \address{Universidad Torcuato Di Tella, Buenos Aires, Argentina}
% \email{ftappata@mail.utdt.edu}
\newdate{date}{14}{07}{2025} % 2025-05-25
\date{\displaydate{date}}

\title[Examen Final]{Datos de Panel: Examen Final}
\begin{abstract}
  Este documento contiene la solución al examen final de la materia \emph{Datos de Panel} en la Universidad Torcuato Di Tella, primer trimestre de 2025.
  El trabajo consiste en la replicación de ciertas tablas y figuras del trabajo de \textcite{al-sadoonSimpleMethodsConsistent2019}, y un análisis de los resultados obtenidos.
  El código usado fue entregado junto a este documento, y se puede encontrar también en el repositorio \url{https://github.com/felipetappata/datos-final}.
  El software usado es Stata, con un uso auxiliar de Python, R y Bash para el procesamiento de \emph{output} y ayuda en la ejecución simultánea de simulaciones.
  El archivo \texttt{README.md} en la raíz del repositorio contiene instrucciones detalladas para la replicación de los resultados.
  El texto principal está escrito en español, pero algunos términos como \enquote{bias} y \enquote{s.e.} se han dejado en inglés para evitar construcciones torpes y resaltar la correspondencia con el trabajo original.
  Lo mismo ocurre con el código; dado que la documentación y los trabajos originales suelen estar en inglés, los comentarios e instrucciones mantienen el idioma.
\end{abstract}
\maketitle
\begin{mdframed}
  \begin{problem}
  \label{prob:1}
  Reproduzca las tablas 1 a 3 del trabajo de Sadoon et al.
  \end{problem}
\end{mdframed}
\begingroup
\renewcommand{\thesolution}{\theproblem}
\begin{solution} % Solution to Problem 1
  \label{sol:1}

  Para la construcción de los Cuadros~\ref{tab:table1}, \ref{tab:table2} y \ref{tab:table3}, replicamos los experimentos de Monte Carlo desarrollados por los autores.
  El proceso generador de datos consiste en un modelo dinámico autorregresivo de primer orden con selección de muestra.
  Específicamente, generamos la variable de resultado de interés según la ecuación de resultado:
  \begin{equation*}
    y_{it}^* = 2 + \rho y_{i,t-1}^* + \alpha_i + \varepsilon_{it} \quad \text{para } t = 2, \ldots, T
  \end{equation*}
  donde $\rho$ toma valores de $0.25$, $0.50$ y $0.75$ para capturar diferentes grados de persistencia.
  Para el período inicial ($t = 1$), utilizamos la forma
  \begin{equation*}
    y_{i1}^* = \frac{2 + \alpha_i + \varepsilon_{i1}}{1 - \rho}.
  \end{equation*}

  El mecanismo de selección se modela mediante dos especificaciones alternativas.
  La especificación estática (modelo~A) se define como:
  \begin{equation*}
    d_{it}^* = a - z_{it} - \eta_i - u_{it}
  \end{equation*}
  mientras que la especificación dinámica (modelo~B) incluye el rezago de la variable de selección:
  \begin{equation*}
    d_{it}^* = a - 0.5 d_{i,t-1} + z_{it} - \eta_i - u_{it}
  \end{equation*}
  En ambos casos, $d_{it} = \mathbf{1}[d_{it}^* > 0]$. La constante $a$ se calibra para que la probabilidad inicial de selección sea $P(d_{it}^* > 0) = 0.85$ en el modelo~A.
  La variable exógena $z_{it}$ se distribuye normal con varianza unitaria.

  La estructura de correlación entre los componentes de error se especifica mediante las ecuaciones
  \begin{align*}
    \alpha_i         & = \alpha_i^0 + 0.5 \eta_i,         \\
    \varepsilon_{it} & = \varepsilon_{it}^0 + 0.5 u_{it},
  \end{align*}
  donde $\alpha_i^0$, $\varepsilon_{it}^0$, $\eta_i$ y $u_{it}$ son independientes con distribución normal estándar.
  Esta parametrización implica una correlación de $0.447$ entre los componentes de error de las ecuaciones de resultado y selección.

  Para cada combinación de parámetros, realizamos $500$ replicaciones con tamaños de muestra iniciales de $N = 500$ y $N = 5000$.
  Generamos series temporales de longitud $T = 17$ a $T = 20$ y descartamos las primeras $13$ observaciones para mitigar efectos de condiciones iniciales, resultando en paneles con dimensión temporal efectiva $T = 7$.\footnote{Los autores mencionan que los resultados no cambian si se generan las $13$ observaciones adicionales y la muestra se comienza con una condición individual para cada individuo (\cite[11]{al-sadoonSimpleMethodsConsistent2019}).}
  Dado que el estimador requiere al menos tres observaciones consecutivas del mismo régimen, una fracción considerable de observaciones no contribuye a la identificación, resultando en una pérdida efectiva de aproximadamente un tercio de las observaciones aun con solo $15\%$ de selección inicial.

  Evaluamos el desempeño de dos estimadores bien conocidos: el estimador GMM-IV en primeras diferencias de Arellano-Bond (AB) y el estimador de sistema (SyS) que combina ecuaciones en niveles y primeras diferencias.
  Para las ecuaciones en primeras diferencias utilizamos como instrumentos todos los rezagos disponibles desde $t-2$ hacia atrás, mientras que para las ecuaciones en niveles empleamos las primeras diferencias rezagadas de la variable dependiente como instrumentos adicionales.

  La implementación computacional se encuentra en los \emph{scripts} de Stata: \texttt{endogenous.do} y \texttt{nonendogenous.do}.
  Para el estimador de Arellano-Bond, empleamos el comando:
  \begin{lstlisting}[language=Stata]
xtabond2 y L.y, gmm(L.y, collapse) nolevel
\end{lstlisting}
  La opción \texttt{collapse} es utilizada por los autores, siguiendo las recomendaciones de \textcite{roodmanHowXtabond2Introduction2009}.\footnote{Comentan, de todos modos, que el problema de proliferación de instrumentos no es un problema en la aplicación dada, debido a la cantidad reducida de períodos (\cite[12]{al-sadoonSimpleMethodsConsistent2019})}
  Para el estimador de sistema, utilizamos:
  \begin{lstlisting}[language=Stata]
xtabond2 y L.y, gmm(L.y, lag(2 .)) iv(L.D.y, equation(level))
\end{lstlisting}
  donde \texttt{lag(2 .)} especifica el uso de rezagos desde $t-2$ hacia atrás como instrumentos GMM, y \texttt{iv(L.D.y, equation(level))} incluye la primera diferencia rezagada como instrumento IV para la ecuación en niveles, siguiendo la propuesta de \textcite{arellanoAnotherLookInstrumental1995}.

  El Cuadro~\ref{tab:table1} muestra los resultados de sesgo promedio y error estándar para los dos estimadores, para experimentos Monte Carlo con diferentes valores de $\rho$ y tamaños de muestra, para las dos especificaciones del modelo de selección, tanto para selección endógena y no.\footnote{Para generar este cuadro, se corren los scripts \texttt{run\_parallel\_N500.sh} y \texttt{run\_parallel\_N5000.sh} para ejecutar en simultáneo diferentes instancias de \texttt{endogenous.do} y \texttt{nonendogenous.do} con los parámetros correspondientes. Los resultados se guardan en archivos \texttt{csv} y luego se procesan con el script \texttt{make\_table\_1.py} para generar el cuadro.}

  \begin{table}[!htbp]
    \centering
    \caption{Sesgo promedio en el modelo $\ar(1)$ ($T = 7$, $500$~replicaciones)}
    \label{tab:table1}
    \input{../code/output/tables/table1.tex}
  \end{table}
  \begin{table}[htbp]
    \begin{threeparttable}[htbp]
      \centering
      \caption{Sesgo promedio en el modelo $\ar(1)$. Análisis de sensibilidad para $N$ chico}
      \label{tab:table2}
      \input{../code/output/tables/table2.tex}
      \begin{tablenotes}[flushleft]
        \item [1] $T = 7$, excepto en el experimento I.
        \item [2] $N = 500$.
        \item [3] Numero de replicaciones: $500$.
      \end{tablenotes}
    \end{threeparttable}
  \end{table}
  \begin{table}[htbp]
    \begin{threeparttable}[htbp]
      \centering
      \caption{Sesgo promedio en el modelo $\ar(1)$. Análisis de sensibilidad para $N$ grande}
      \label{tab:table3}
      \input{../code/output/tables/table3.tex}
      \begin{tablenotes}[flushleft]
        \item [1] $T = 7$, excepto en el experimento I.
        \item [2] $N = 5000$.
        \item [3] Numero de replicaciones: $500$.
      \end{tablenotes}
    \end{threeparttable}
  \end{table}

  Los Cuadros~\ref{tab:table2} y \ref{tab:table3} son el resultado de un análisis de sensibilidad para los tamaños de muestra chico ($N = 500$) y grande ($N = 5000$), respectivamente.
  El análisis de sensibilidad, o robustez, consiste en diseñar cinco \enquote{experimentos} que modifican el escenario original para mostrar que los resultados no se modifican significativamente.
  Los experimentos son los siguientes (\cite[16,17]{al-sadoonSimpleMethodsConsistent2019}).
  \begin{enumerate}[label=\textbf{Experimento \Roman*:}, ref=\Roman*, leftmargin=*, itemsep=0.5em]
    \item \label{exp:short-T} \textbf{$\boldsymbol{T}$ corto.} Consiste en reducir la máxima dimensión longitudinal del panel observado de $T = 7$ a $T = 4$, incrementando el número de observaciones descartadas de 13 a 16. El efecto sobre el sesgo medio es moderado para ambos estimadores y ambos tamaños muestrales, pero incrementa sustancialmente la varianza, especialmente para el estimador AB con valores altos de $\rho$.
    \item \label{exp:more-selection} \textbf{Más selección.} Consiste en aumentar el grado de selección de muestra del $15\%$ al $25\%$, modificando la constante $a$ de $1.794$ a aproximadamente $1.168$. Aumenta el sesgo medio muy levemente y la varianza por la reducción en la cantidad de observaciones disponibles.
    \item \label{exp:variance-ratio} \textbf{Incrementar el ratio de varianzas.} Consiste en aumentar el ratio de la varianza del componente de heterogeneidad individual respecto a la varianza del componente variante en el tiempo de la ecuación de resultado, estableciendo $\sigma_\eta = 2$ en lugar de $\sigma_\eta = 1$. El efecto sobre el sesgo medio es limitado para ambos estimadores, siendo más pronunciado en muestras pequeñas.
    \item \label{exp:reduce-correlation} \textbf{Reducir la correlación de errores.} Consiste en reducir los parámetros de correlación de $\theta = \vartheta = 0.5$ a $\theta = \vartheta = 0.25$. Se reduce el sesgo medio para ambos estimadores en todos los escenarios considerados, confirmando que menor correlación entre componentes de error facilita la estimación.
    \item \label{exp:time-varying} \textbf{Componentes del error no estacionarios y variantes en el tiempo.} Introduce heterogeneidad temporal multiplicando $u_{it}$ por un proceso Bernoulli que toma valores 1 o 2, y permitiendo que el parámetro $\vartheta$ varíe aleatoriamente entre $0.5$, $1$ y $2$. El sesgo medio se reduce significativamente para ambos estimadores, siendo el efecto más notable en muestras pequeñas.
  \end{enumerate}

  La implementación de estos experimentos se realiza mediante scripts especializados (llamados en el repositorio \texttt{experiment1.do} a \texttt{experiment5.do}) que modifican parámetros específicos del proceso generador de datos base.
  Por ejemplo, el Experimento~\ref{exp:short-T} modifica la variable \texttt{T\_discard} de 13 a 16, mientras que el Experimento~\ref{exp:more-selection} recalcula la constante $a$ para lograr la probabilidad de selección deseada.
  El Experimento~\ref{exp:variance-ratio} simplemente cambia \texttt{sigma\_eta} de 1 a 2, y el Experimento~\ref{exp:reduce-correlation} reduce \texttt{theta\_param} y \texttt{vartheta\_param} de 0.5 a 0.25.
  El Experimento~\ref{exp:time-varying} es el más complejo, introduciendo variabilidad temporal mediante:
  \begin{lstlisting}[language=Stata, basicstyle=\ttfamily]
gen bernoulli_process = (runiform() > 0.5) + 1
replace u_it = u_it * bernoulli_process
gen vartheta_random = (0.5, 1, 2)[ceil(runiform()*3)]
replace eps_it = eps_i0 + vartheta_random * u_it
\end{lstlisting}

  Como podemos observar en los cuadros, los resultados confirman las conclusiones principales del trabajo original.
  En el Cuadro~\ref{tab:table1}, el estimador AB muestra un sesgo que crece sistemáticamente con el parámetro autorregresivo $\rho$ cuando el tamaño muestral es pequeño ($N = 500$), llegando a ser considerable cuando $\rho = 0.75$.
  Al incrementar el tamaño muestral a $N = 5000$, el sesgo promedio del estimador AB se reduce sustancialmente.

  Por el contrario, el estimador System muestra un sesgo muy pequeño para $N = 500$ (nunca excediendo el uno por ciento), y aún menor cuando $N = 5000$.
  Bajo selección endógena, no detectamos cambios significativos en los resultados de sesgo para el estimador AB, mientras que el estimador System siempre muestra un sesgo muy pequeño (entre 1 y 2.25 por ciento para diferentes valores de $\rho$).
  Notablemente, el sesgo del estimador System se vuelve más evidente conforme crece el tamaño muestral bajo selección endógena.

  Los ejercicios de sensibilidad presentados en los Cuadros~\ref{tab:table2} y~\ref{tab:table3} confirman las lecciones principales del análisis: el estimador AB está moderadamente sesgado cuando $N$ es pequeño o moderado, y su sesgo se acerca a cero cuando $N$ es grande.
  El estimador System está siempre moderadamente sesgado pero de manera estable.
  La reducción de la dimensión temporal (Experimento~\ref{exp:short-T}) incrementa la varianza estimada pero tiene un efecto muy pequeño sobre el sesgo promedio para ambos estimadores.
  El incremento en el grado de selección muestral (Experimento~\ref{exp:more-selection}) aumenta el sesgo promedio muy levemente pero incrementa su varianza debido a la reducción significativa en el número de observaciones.
  Estos resultados implican que el estimador System es especialmente recomendable cuando el tamaño muestral es pequeño o incluso moderado (por ejemplo, $N \leq 2000$) y menos crítico cuando el tamaño muestral es mayor.

\end{solution}
\endgroup
\begin{mdframed}
  \begin{problem}
  \label{prob:2}
  Reproduzca la Figura~1 del trabajo de Sadoon et al.
  \end{problem}
\end{mdframed}
\begingroup
\renewcommand{\thesolution}{\theproblem}
\begin{solution} % Solution to Problem 2
  \label{sol:2}

  \begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \resizebox{\textwidth}{!}{\input{../code/output/fig1/panel1_bias_rho025.tex}}
      \caption{Sesgo medio, $\rho = 0.25$}
      \label{fig:panel1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \resizebox{\textwidth}{!}{\input{../code/output/fig1/panel2_bias_rho050.tex}}
      \caption{Sesgo medio, $\rho = 0.50$}
      \label{fig:panel2}
    \end{subfigure}
    \vfill
    \begin{subfigure}[b]{0.5\textwidth}
      \centering
      \resizebox{\textwidth}{!}{\input{../code/output/fig1/panel3_bias_rho075.tex}}
      \caption{Sesgo medio, $\rho = 0.75$}
      \label{fig:panel3}
    \end{subfigure}
    \caption{Sesgo promedio de estimadores AB y System en la muestra completa ($N\times T$ observaciones) y la muestra con selección endógena}
    \label{fig:fig1}
  \end{figure}

  La Figura~\ref{fig:fig1} replica la Figura~1 del trabajo original mediante simulaciones de para diferentes parámetros de persistencia y diferentes tamaños de muestra.\footnote{Como se describe en el \texttt{README}, el proceso de simulación se implementa mediante el script \texttt{run\_figure1\_sims.sh}, que ejecuta simulaciones paralelas para cada combinación de parámetros $(N, \rho, \text{modelo})$.
    Para cada configuración, el script ejecuta tanto simulaciones con selección endógena como estimaciones en la muestra completa, generando los datos necesarios para las cuatro series mostradas en cada panel: AB (all), AB (select), System (all), y System (select).
    Las simulaciones cubren tamaños muestrales desde $N = 200$ hasta $N = 5000$, permitiendo observar la evolución del sesgo a través de diferentes escalas de muestra.
    Una vez completadas las simulaciones, el script \texttt{fig1.R} procesa los resultados y genera las visualizaciones utilizando el paquete \texttt{tikzDevice} de R para compatibilidad directa con \LaTeX.
    El código genera tres paneles separados correspondientes a $\rho = 0.25, 0.50, 0.75$, cada uno como un archivo \texttt{.tex} independiente que contiene comandos TikZ.}
  En particular, hay un gráfico para cada parámetro de persistencia $\rho \in \{0.25, 0.50, 0.75\}$, en el cual se muestra la evolución de los sesgos promedio en las simulaciones Monte Carlo para los estimadores Arellano-Bond (AB) y System (SyS) sobre la muestra completa (\emph{all}) y sobre la muestra con selección endógena (\emph{select}), para cada tamaño de muestra
  \begin{equation*}
    N \in \{200, 400, 600, 800, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000\}.
  \end{equation*}

  Los resultados confirman los patrones fundamentales identificados en el trabajo original y observables en el Cuadro~\ref{tab:table1}.
  Para el estimador AB, observamos una reducción dramática (en términos absolutos) del sesgo a medida que aumenta el tamaño muestral, siendo esta mejora particularmente pronunciada para valores altos de $\rho$.
  En el panel~\ref{fig:panel3} con $\rho = 0.75$, por ejemplo, el sesgo del estimador AB es notable para muestras pequeñas pero converge rápidamente hacia cero cuando $N$ crece.

  El estimador System exhibe un comportamiento cualitativamente diferente: su sesgo permanece relativamente estable y pequeño a través de todos los tamaños muestrales considerados y para todos los valores de persistencia.
  Esta estabilidad es evidente en los tres paneles, donde las líneas correspondientes al estimador System se quedan alrededor de valores cercanos a cero sin mostrar la tendencia decreciente (en valor absoluto) dramática que caracteriza al sesgo del estimador AB.

\end{solution}
\endgroup
\begin{mdframed}
  \begin{problem}
  \label{prob:3}
  Comente sobre el sesgo promedio de las estimaciones a medida que aumenta el valor del parámetro de persistencia $\rho$ para ambos estimadores: Arellano-Bond y SyS. ¿Varían las conclusiones al trabajar con muestras pequeñas o grandes?
  \end{problem}
\end{mdframed}
\begingroup
\renewcommand{\thesolution}{\theproblem}
\begin{solution} % Solution to Problem 3
  \label{sol:3}
  A partir de la implementación de simulaciones de Monte Carlo siguiendo la metodología de \textcite{al-sadoonSimpleMethodsConsistent2019}, analizamos las propiedades de muestra finita de los estimadores de Arellano-Bond (AB) y System (SyS) bajo diferentes grados de persistencia para el proceso autorregresivo.

  Los resultados del Cuadro~\ref{tab:table1} revelan patrones claramente diferenciados entre ambos estimadores.
  Para el estimador AB, el sesgo, en valor absoluto, incrementa sistemáticamente con el parámetro de persistencia $\rho$, exhibiendo un crecimiento particularmente pronunciado cuando $\rho$ se acerca a la unidad.
  Este comportamiento es consistente con los problemas de instrumentos débiles que caracterizan al estimador en primeras diferencias cuando la serie presenta alta persistencia.

  El estimador System muestra un comportamiento cualitativamente diferente.
  Su sesgo permanece relativamente estable y pequeño para todos los valores de $\rho$ considerados, sin mostrar el deterioro sistemático que caracteriza al estimador AB.
  Esta estabilidad refleja la eficiencia de las condiciones de momentos adicionales en niveles que proporcionan información extra sobre los parámetros de interés.

  Las diferencias entre muestras pequeñas ($N = 500$) y grandes ($N = 5000$) son sustanciales y asimétricas entre estimadores.
  Para muestras grandes, el sesgo del estimador AB se reduce drásticamente en todos los casos, acercándose a cero como es esperado por su consistencia.
  Esta mejora es especialmente notable para valores altos de $\rho$, donde la ganancia en precisión es considerable.
  Es decir, la \emph{mejora} del sesgo del estimador AB cuando aumenta el tamaño de la muestra es más pronunciada para valores altos de $\rho$, como podemos ver al comparar la Figura~\ref{fig:panel1} que tiene $\rho = 0.25$ con la Figura~\ref{fig:panel3} que tiene $\rho = 0.75$.

  El estimador System mantiene un sesgo bajo y relativamente estable, independientemente de cual sea el tamaño muestral.

  Los errores estándar exhiben el comportamiento esperado para ambos estimadores: disminuyen al incrementarse el tamaño muestral.
  Sin embargo, el estimador AB consistentemente presenta mayor variabilidad que el System, especialmente para valores altos de $\rho$.

  La presencia de selección endógena introduce modificaciones modestas pero sistemáticas en las propiedades de ambos estimadores.
  Para el estimador AB, que teóricamente debería mantener su consistencia bajo selección endógena, los efectos son generalmente pequeños y en varias especificaciones del experimento se reduce el sesgo en términos absolutos cuando hay selección endógena respecto al caso de selección no endógena.

  El estimador System muestra un incremento más sistemático del sesgo bajo selección endógena, particularmente evidente en muestras grandes y valores altos de $\rho$.
  Este comportamiento es consistente con la invalidez teórica de las condiciones de momentos en niveles bajo selección endógena, aunque la magnitud, a nivel práctico, del sesgo permanece manejable.
  La Figura~\ref{fig:fig1} ilustra claramente estas diferencias, y se puede ver que para muestras grandes con selección endógena parece ser preferible el estimador AB al System, y para muestras chicas el System es preferible al AB, en especial cuando $\rho$ es alto.

  Los experimentos reportados en los Cuadros~\ref{tab:table2} y~\ref{tab:table3} confirman la robustez general de nuestros hallazgos principales.
  La reducción de la dimensión temporal (Experimento~\ref{exp:short-T}) intensifica los problemas de ambos estimadores pero preserva su ordenación relativa.
  Los experimentos que modifican las correlaciones entre componentes de error o introducen heterogeneidad adicional generalmente mantienen las conclusiones cualitativas, aunque pueden alterar las magnitudes específicas del sesgo.

  En línea con las conclusiones del trabajo original, nuestros resultados muestran que en muestras pequeñas, el estimador System presenta una performance consistentemente superior al AB, exhibiendo menor sesgo y varianza para todos los valores de $\rho$ considerados.
  Esta ventaja es particularmente pronunciada para valores altos del parámetro de persistencia, donde el estimador AB sufre problemas severos de instrumentos débiles.

  En muestras grandes, la brecha entre estimadores se reduce sustancialmente.
  La presencia de selección endógena no altera cualitativamente estas conclusiones, aunque si podemos decir en este caso que para muestras grandes en las especificaciones estudiadas, con selección endógena el estimador AB muestra un sesgo menor en términos absolutos que el estimador system.

  En la práctica, si estamos trabajando con paneles dinámicos potencialmente desbalanceados, estos resultados sugieren que el uso directo de estimadores GMM-IV estándar, particularmente el System en muestras pequeñas y con parámetros de persistencia mayores, puede proveer estimaciones razonablemente precisas sin necesidad de corrección explícita por selección muestral, exhibiendo menor sesgo que el estimador AB, pero que esta ventaja práctica desaparece cuando $N$ es grande, especialmente cuando hay selección endógena.

\end{solution}
\endgroup
\printbibliography
\end{document}